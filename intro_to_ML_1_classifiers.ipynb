{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theora/LawAndAI/blob/main/intro_to_ML_1_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CXcVWSlLv6o"
      },
      "source": [
        "# ALAAI HW 3 (Introduction to ML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtjltvciL8fd"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This set of exercises is intended to introduce students to fundamental steps that are necessary in carrying out a basic supervised ML experiment. The goal of the exercise is to make students aware of all the steps that go into such an experiment, beginning with acquisition and preprocessing of data and finishing with the evaluation of the experimental results.\n",
        "\n",
        "It is important to have access to the internet in order to download the required resources and refer to online documentation.\n",
        "\n",
        "Begin by reading Section 1 (Background and Motivation) and Section 3 (Data Set) of the [Improving Sentence Retrieval from Case Law for Statutory Interpretation](http://savelka.net/docs/2019ICAIL.pdf) paper. Despite the paper is about ranking the sentences we will simply treat the problem as multi-label classification task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdCbPhaML6b0"
      },
      "source": [
        "## Get the Data\n",
        "\n",
        "First you are asked to execute the cell below. Note the exclamation marks at the beginning of the lines. In Colab this means that the code is not understood as Python but rather as [bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) code which is executed as such.\n",
        "\n",
        "The code clones [the repository](https://github.com/jsavelka/statutory_interpretation) from GitHub (git clone). In case you would like to learn more about git and GitHub you can go over [this article](https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsmGKB15Nsqp"
      },
      "source": [
        "WARNING: Before you proceed create your own copy of this notebook. Under File click \"Save a Copy in Drive\". Continue your work on the copy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wudjlHq2anxl"
      },
      "source": [
        "!git clone https://github.com/jsavelka/statutory_interpretation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QS_chz4N-WI"
      },
      "source": [
        "Executing the below cell will list the files in the repository you just cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtj6FNKcMqsw"
      },
      "source": [
        "!ls statutory_interpretation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeGu6tHPOSys"
      },
      "source": [
        "Unzip the archive with the documents related to the “common business purpose” term (`common_business_purpose.zip`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iezbmKTIMMRX"
      },
      "source": [
        "!unzip statutory_interpretation/common_business_purpose.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzugOqoDNKOg"
      },
      "source": [
        "## Load and Explore the Data\n",
        "\n",
        "Using the json module load the data from the `common_business_purpose-sentence.json` file. Follow the instruction provided in the TODO. Executing the cell before completing the task will result in an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPeCuARhbUiy"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "PWD = Path()\n",
        "IEV_FILE = PWD/'...'  # TODO: Replace the three dots with the file name."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEaclX9BQpSZ"
      },
      "source": [
        "Load the json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsuifdy3bl4B"
      },
      "source": [
        "with open(IEV_FILE, 'r') as json_f:\n",
        "    cbp_data = json.load(json_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDJYeM9NQ1jK"
      },
      "source": [
        "Explore the object you have just loaded into memory. Start with understanding what kind of object it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNeaNPSwRD2a"
      },
      "source": [
        "print(type(cbp_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpDai2QRJYZ"
      },
      "source": [
        "Knowing the object is a dictionary determine what keys it has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDsaZsfjRQJW"
      },
      "source": [
        "print(cbp_data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hj86UgARdYG"
      },
      "source": [
        "Explore one of the objects under any of the keys. Follow the instruction provided in the TODO. Executing the cell before completing the task will result in an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exQs3sBlRW5Q"
      },
      "source": [
        "pprint(cbp_data['...'])  # TODO: Replace the three dots with any of the keys."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9wZOh9PTHxe"
      },
      "source": [
        "Finally, determine how many documents there are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReXsH51CNmBs"
      },
      "source": [
        "print(len(cbp_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMlAaTnzTlPo"
      },
      "source": [
        "For each sentence extract the label and the text. Make sure to keep correct pairing between labels and sentences. For example, you can create one list for labels and one list for the texts but make sure that both lists are ordered accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnPioIQRbt9T"
      },
      "source": [
        "labels = []\n",
        "texts = []\n",
        "for sent_data in cbp_data.values():\n",
        "    labels.append(sent_data['label'])\n",
        "    texts.append(sent_data['text'])\n",
        "print(f'Len labels: {len(labels)}; Len features: {len(texts)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOE7Om8btlC"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "This Colab will walk you through several exercises. Follow the instructions and write your answers to the individual questions into a separate file (MS Word docx, plain text, or any other common format). The questions are meant to be answered in the order in which they are asked.\n",
        "\n",
        "NOTE: Only the underlined items are supposed to be reported in your homework submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm9V_6Wwb7ho"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Generate a bar chart describing the distribution of the labels. <ins>Show the bar chart in your report and comment on the balance of the classes</ins>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-H0dHWpgAVz"
      },
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sentence_types, counts = zip(*Counter(labels).items())\n",
        "indexes = np.arange(len(sentence_types))\n",
        "plt.title('Label Distribution')\n",
        "plt.bar(indexes, counts)\n",
        "plt.xticks(indexes, sentence_types)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYNYX9A_RCC9"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Split your data set into the training, validation, and test set. Use 50/25/25 split. <ins>Explain the importance of dividing the data set into a training and test set.</ins>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrl0eCsKfP30"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(texts, labels,\n",
        "                                                    test_size=0.5, shuffle=True)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp,\n",
        "                                                test_size=0.5, shuffle=True)\n",
        "\n",
        "print(f'Len train: {len(X_train)} ({len(y_train)})')\n",
        "print(f'Len valid: {len(X_val)} ({len(y_val)})')\n",
        "print(f'Len test: {len(X_test)} ({len(y_test)})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI-n9_UhdBV6"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Vectorize the data set using the `CountVectorizer` from the `sklearn` library of modules. <ins>Explain the purpose of transforming the text of the documents into vectors.</ins>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23NkXCZMdW1R"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_val_counts = count_vect.transform(X_val)\n",
        "X_test_counts = count_vect.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKAOSWfPcVL5"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Train a `Nearest Neighbors Classifier` using `5` closest data points as neighbors. Follow the instruction provided in the TODO. Executing the cell before completing the task will result in an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaAInJHRhSNP"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)  # TODO: Replace the three dots with the number of neighbors.\n",
        "neigh.fit(X_train_counts, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWj66CZeWjw"
      },
      "source": [
        "Evaluate the fitted models on the validation set. <ins>Report per class Precision, Recall, and F1-measure as well as a confusion matrix for your classifiers.</ins>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkpcI2i7hinQ"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred_nn = neigh.predict(X_val_counts)\n",
        "print(classification_report(y_val, pred_nn))\n",
        "disp = plot_confusion_matrix(neigh, X_val_counts, y_val,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in neigh.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xSUoY7geytJ"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Train a `Decision Tree Classifier` using `4` as maximum tree depth. Follow the instruction provided in the TODO. Executing the cell before completing the task will result in an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbGsy4ZoKM-"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42, max_depth=4)  # TODO: Replace the three dots with the maximum tree depth.\n",
        "tree.fit(X_train_counts, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wPQurOfMnR"
      },
      "source": [
        "Evaluate the fitted models on the validation set. <ins>Report per class Precision, Recall, and F1-measure as well as a confusion matrix for your classifiers.</ins>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu3hrFkEoch6"
      },
      "source": [
        "pred_tree = tree.predict(X_val_counts)\n",
        "print(classification_report(y_val, pred_tree))\n",
        "disp = plot_confusion_matrix(tree, X_val_counts, y_val,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in neigh.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTC-Ch3-fos3"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Train a `Logistic Regression Classifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i5W4Mvap7sV"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(random_state=42)\n",
        "lr_clf.fit(X_train_counts, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrKFDuFHf-wJ"
      },
      "source": [
        "Evaluate the fitted models on the validation set. <ins>Report per class Precision, Recall, and F1-measure as well as a confusion matrix for your classifiers.</ins>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lasr7BSMqXqe"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred_lr = lr_clf.predict(X_val_counts)\n",
        "print(classification_report(y_val, pred_lr))\n",
        "disp = plot_confusion_matrix(lr_clf, X_val_counts, y_val,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in lr_clf.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYkOFfDPgT6v"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Compare the three classifiers on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqrXE6DeyrlC"
      },
      "source": [
        "# nearest neigbors\n",
        "pred_nn = neigh.predict(X_test_counts)\n",
        "# decision tree\n",
        "pred_tree = tree.predict(X_test_counts)\n",
        "# logistic regression\n",
        "pred_lr = lr_clf.predict(X_test_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNu7thqrgn61"
      },
      "source": [
        "<ins>Elaborate on which of them performs the best. Explain why are you identifying the one as the best performing.</ins>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p80r-pvPzzhd"
      },
      "source": [
        "# compare using classification reports\n",
        "print('NEAREST NEIGHBORS')\n",
        "print(classification_report(y_test, pred_nn))\n",
        "print('DECISION TREE')\n",
        "print(classification_report(y_test, pred_tree))\n",
        "print('LOGISTIC REGRESSION')\n",
        "print(classification_report(y_test, pred_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d74VMdZn0V4v"
      },
      "source": [
        "# compare using confusion matrices\n",
        "disp = plot_confusion_matrix(neigh, X_test_counts, y_test,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in neigh.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)\n",
        "\n",
        "disp = plot_confusion_matrix(tree, X_test_counts, y_test,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in tree.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)\n",
        "\n",
        "disp = plot_confusion_matrix(lr_clf, X_test_counts, y_test,\n",
        "                             display_labels=[a.split()[0] for a\n",
        "                                             in lr_clf.classes_],\n",
        "                             values_format='.0f',\n",
        "                             cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}